{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Two-Stage AI Pipeline: From Unstructured Text to Personalized Email\n",
        "\n",
        "In this notebook, we'll build a practical AI pipeline that automates a recruiter's workflow:\n",
        "1.  **Extract Data**: Turn unstructured LinkedIn profile text into structured JSON.\n",
        "2.  **Generate Content**: Use that structured data to write a personalized outreach email.\n",
        "3.  **Evaluate Quality**: Build an **LLM-as-a-Judge** to automatically score the personalization of our emails.\n",
        "\n",
        "We will explore prompt engineering techniques (like schema definitions and persona constraints) to iterate from a basic baseline to a working prototype.\n",
        "\n",
        "This will give us the building blocks for creating more reliable and testable AI applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "First, let's set up our environment and API credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from google import genai\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the client (automatically finds GOOGLE_API_KEY)\n",
        "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load LinkedIn Profile Data\n",
        "\n",
        "We'll use the LinkedIn profile text from Workshop 1 as our test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profile loaded! First 500 characters:\n",
            "Contact\n",
            "hugobowne@gmail.com\n",
            "www.linkedin.com/in/hugo-bowne-\n",
            "anderson-045939a5 (LinkedIn)\n",
            "hugobowne.github.io/ (Personal)\n",
            "Hugo Bowne-Anderson\n",
            "Data and AI scientist, consultant. writer, educator, machine learner,\n",
            "podcaster.\n",
            "Darlinghurst, New South Wales, Australia\n",
            "Top Skills\n",
            "Artificial Intelligence (AI)\n",
            "Data Science\n",
            "Developer Relations\n",
            "Languages\n",
            "French (Elementary)\n",
            "Summary\n",
            "I'm an independent data and AI scientist, consultant, writer, educator\n",
            "& podcaster. My interests include promoting data & AI l\n",
            "\n",
            "Total length: 4900 characters\n"
          ]
        }
      ],
      "source": [
        "# Read the LinkedIn profile data\n",
        "with open('../apps/data/hba.txt', 'r') as f:\n",
        "    linkedin_profile = f.read()\n",
        "\n",
        "print(\"Profile loaded! First 500 characters:\")\n",
        "print(linkedin_profile[:500])\n",
        "print(f\"\\nTotal length: {len(linkedin_profile)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: LinkedIn Profile → Structured JSON\n",
        "\n",
        "### Goal\n",
        "Extract clean, structured JSON from messy LinkedIn profile text.\n",
        "\n",
        "### Target Schema\n",
        "We want to extract:\n",
        "- `name`: Full name\n",
        "- `current_title`: Current job title\n",
        "- `location`: Current location\n",
        "- `years_experience`: Approximate total years of experience\n",
        "- `top_skills`: List of 3-5 key skills\n",
        "- `recent_roles`: List of 2-3 most recent positions (title, company, duration)\n",
        "- `education`: Highest degree and institution\n",
        "\n",
        "Let's test 5 different prompt engineering approaches and see which works best.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 1: Minimal Prompt (Baseline)\n",
        "\n",
        "Start simple - just ask for JSON extraction with no structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Variation 1: Minimal Prompt ===\n",
            "```json\n",
            "{\n",
            "  \"name\": \"Hugo Bowne-Anderson\",\n",
            "  \"headline\": \"Data and AI scientist, consultant. writer, educator, machine learner, podcaster.\",\n",
            "  \"location\": \"Darlinghurst, New South Wales, Australia\",\n",
            "  \"contact\": {\n",
            "    \"email\": \"hugobowne@gmail.com\",\n",
            "    \"linkedin\": \"www.linkedin.com/in/hugo-bowne-anderson-045939a5\",\n",
            "    \"personal_website\": \"hugobowne.github.io/\"\n",
            "  },\n",
            "  \"summary\": \"I'm an independent data and AI scientist, consultant, writer, educator & podcaster. My interests include promoting data & AI literacy/fluency, helping to spread data skills through organizations and society and lowering the barrier to entry for data science, analysis, and machine learning. Previously, I was Head of Developer Relations at Outerbounds, a company committed to building infrastructure that provides a solid foundation for machine learning applications of all shapes and sizes. I am also the host of the industry podcast Vanishing Gradients. I was previously Head of Marketing and Data Science Evangelism at Coiled, building solutions for scalable data science and machine learning in Python. Before this, I was at DataCamp, a data science training company educating over 4 million learners worldwide through interactive courses on the use of Python, R, SQL, Git, Bash and Spreadsheets in a data science context. While there, I spearheaded the development of over 25 courses in DataCamp’s Python curriculum, impacting over 250,000 learners worldwide through my own courses. I hosted and produced the data science podcast DataFramed, in which I used long-format interviews with working data scientists to delve into what actually happens in the space and what impact it can and does have.\",\n",
            "  \"skills\": [\n",
            "    \"Artificial Intelligence (AI)\",\n",
            "    \"Data Science\",\n",
            "    \"Developer Relations\"\n",
            "  ],\n",
            "  \"languages\": [\n",
            "    {\n",
            "      \"language\": \"French\",\n",
            "      \"proficiency\": \"Elementary\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"Freelance\",\n",
            "      \"title\": \"Independent Data and AI Scientist\",\n",
            "      \"start_date\": \"July 2024\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"duration\": \"1 year 6 months\",\n",
            "      \"description\": null\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Outerbounds\",\n",
            "      \"title\": \"Head of Developer Relations\",\n",
            "      \"start_date\": \"February 2022\",\n",
            "      \"end_date\": \"August 2024\",\n",
            "      \"duration\": \"2 years 7 months\",\n",
            "      \"description\": null\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Coiled\",\n",
            "      \"title\": \"Head of Data Science Evangelism and Marketing\",\n",
            "      \"start_date\": \"May 2020\",\n",
            "      \"end_date\": \"October 2021\",\n",
            "      \"duration\": \"1 year 6 months\",\n",
            "      \"description\": null\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DataCamp\",\n",
            "      \"title\": \"Data Scientist\",\n",
            "      \"start_date\": \"September 2017\",\n",
            "      \"end_date\": \"May 2020\",\n",
            "      \"duration\": \"2 years 9 months\",\n",
            "      \"description\": null\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DataCamp\",\n",
            "      \"title\": \"Curriculum Engineer (Python)\",\n",
            "      \"start_date\": \"March 2016\",\n",
            "      \"end_date\": \"May 2020\",\n",
            "      \"duration\": \"4 years 3 months\",\n",
            "      \"description\": \"DataCamp is a Boston-based startup that provides online, interactive training in data science. Founded in 2013, the company participated in TechStars NYC during the spring of 2015, received their first round of VC funding soon after, and now has over 350,000 registered users worldwide. At DataCamp, I am responsible for building out the Python curriculum. This involves everything from mapping out long-term curriculum goals to devising courses to (the best part!) working with state-of-the-art instructors from academia, industry and development to build interactive data science courses. We provide instructors the opportunity to significantly expand their reach, influence, and impact, while also supplementing their income through our generous revenue sharing program. For more reasons why you should consider working with us, see datacamp.com/create\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Yale University\",\n",
            "      \"title\": \"Postdoctoral Associate/Writer\",\n",
            "      \"start_date\": \"2013\",\n",
            "      \"end_date\": \"March 2016\",\n",
            "      \"duration\": \"3 years\",\n",
            "      \"description\": \"--Developing statistical models for the growth and structure of neurons, in collaboration with experimentalists (we use the Class IV sensory neuron in Drosophila larvae as a model system). Daily tasks include constructing master equations, developing analytical solutions and performing simulations via numerical integration and Monte Carlo methods, along with devising probability models, implementing statistical tests and analyzing large amounts of data. -- Developing quantification methods for gene-expresssion and alternative splicing across a variety of organisms. To do so, we mine publicly available RNA-seq datasets (>10^6 data points), develop statistical models, utilize statistical hypothesis tests and implement both supervised and unsupervised learning models on big data.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Max Planck Institute for Molecular Cell Biology and Genetics\",\n",
            "      \"title\": \"Postdoctoral Fellow\",\n",
            "      \"start_date\": \"2011\",\n",
            "      \"end_date\": \"2013\",\n",
            "      \"duration\": \"2 years\",\n",
            "      \"description\": \"--Predictive mathematical modeling of microtubule dynamics; analyzed in vitro data to construct a model that accounted for the multistep nature of catastrophe and the relative insensitivity of lifetime with respect to tubulin concentration; techniques employed include analytic solutions to master equations developed from our models, parameter estimation (e.g. maximum likelihood estimation), implementation of Monte Carlo simulations and statistical tests. -- Acted as statistical/mathematical consultant for biologists in the lab: this included helping experimentalists to form their hypotheses precisely and mathematically, to ask well-posed scientific questions, and to analyze their data using statistical hypothesis testing.\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"institution\": \"UNSW Australia\",\n",
            "      \"degree\": \"Doctor of Philosophy (PhD)\",\n",
            "      \"field_of_study\": \"Pure Mathematics\",\n",
            "      \"start_year\": 2006,\n",
            "      \"end_year\": 2011\n",
            "    },\n",
            "    {\n",
            "      \"institution\": \"University of Sydney\",\n",
            "      \"degree\": \"Bachelor of Science (B.S.) (First Class Honors)\",\n",
            "      \"field_of_study\": \"Mathematics, English Literature\",\n",
            "      \"start_year\": 2001,\n",
            "      \"end_year\": 2005\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt_v1 = f\"\"\"Extract the key information from this LinkedIn profile as JSON:\n",
        "\n",
        "{linkedin_profile}\n",
        "\"\"\"\n",
        "\n",
        "response_v1 = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt_v1,\n",
        ")\n",
        "\n",
        "print(\"=== Variation 1: Minimal Prompt ===\")\n",
        "print(response_v1.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 2: With Schema Definition, JSON Mode, and Error Handling\n",
        "\n",
        "This variation combines explicit field definitions, JSON mode, and missing data instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Variation 2\n",
            "{\n",
            "  \"name\": \"Hugo Bowne-Anderson\",\n",
            "  \"current_title\": \"Independent Data and AI Scientist\",\n",
            "  \"location\": \"Darlinghurst, New South Wales, Australia\",\n",
            "  \"years_experience\": 15,\n",
            "  \"top_skills\": [\n",
            "    \"Artificial Intelligence (AI)\",\n",
            "    \"Data Science\",\n",
            "    \"Developer Relations\"\n",
            "  ],\n",
            "  \"recent_roles\": [\n",
            "    {\n",
            "      \"title\": \"Independent Data and AI Scientist\",\n",
            "      \"company\": \"Freelance\",\n",
            "      \"duration\": \"July 2024 - Present (1 year 6 months)\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Developer Relations\",\n",
            "      \"company\": \"Outerbounds\",\n",
            "      \"duration\": \"February 2022 - August 2024 (2 years 7 months)\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Data Science Evangelism and Marketing\",\n",
            "      \"company\": \"Coiled\",\n",
            "      \"duration\": \"May 2020 - October 2021 (1 year 6 months)\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": \"Doctor of Philosophy (PhD), Pure Mathematics from UNSW Australia\"\n",
            "}\n",
            "\n",
            "Valid JSON!\n",
            "\n",
            "Extracted fields: ['name', 'current_title', 'location', 'years_experience', 'top_skills', 'recent_roles', 'education']\n"
          ]
        }
      ],
      "source": [
        "prompt_v2 = f\"\"\"Extract structured information from the LinkedIn profile below.\n",
        "\n",
        "Required fields:\n",
        "- name (string): Full name of the person\n",
        "- current_title (string): Most recent job title\n",
        "- location (string): Current location\n",
        "- years_experience (integer): Total years of professional experience (estimate if needed)\n",
        "- top_skills (array): 3-5 key skills or areas of expertise\n",
        "- recent_roles (array): 2-3 most recent positions with title, company, and duration\n",
        "- education (string): Highest degree and institution\n",
        "\n",
        "Important rules:\n",
        "- If a field is missing or unclear, use null for strings or [] for arrays\n",
        "- For years_experience, calculate from experience section dates\n",
        "- Extract skills from the profile text, skills section, or infer from roles\n",
        "- Return ONLY valid JSON, no markdown formatting\n",
        "\n",
        "<linkedin_profile>\n",
        "{linkedin_profile}\n",
        "</linkedin_profile>\n",
        "\"\"\"\n",
        "\n",
        "response_v2 = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt_v2,\n",
        "    config={\n",
        "        \"response_mime_type\": \"application/json\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"=== Variation 2\")\n",
        "print(response_v2.text)\n",
        "\n",
        "# Try to parse and validate\n",
        "try:\n",
        "    parsed_v2 = json.loads(response_v2.text)\n",
        "    print(\"\\nValid JSON!\")\n",
        "    print(f\"\\nExtracted fields: {list(parsed_v2.keys())}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\n Invalid JSON\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Structured Data → Personalized Recruiter Email\n",
        "\n",
        "### Goal\n",
        "Generate a personalized, professional recruiter outreach email from the structured candidate data.\n",
        "\n",
        "### Job Position Context\n",
        "Let's say we're recruiting for a \"Senior AI/ML Engineer\" position. We'll test different approaches to see what produces the best emails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Extracted Candidate Data ===\n",
            "{\n",
            "  \"name\": \"Hugo Bowne-Anderson\",\n",
            "  \"current_title\": \"Independent Data and AI Scientist\",\n",
            "  \"location\": \"Darlinghurst, New South Wales, Australia\",\n",
            "  \"years_experience\": 13,\n",
            "  \"top_skills\": [\n",
            "    \"Artificial Intelligence (AI)\",\n",
            "    \"Data Science\",\n",
            "    \"Developer Relations\",\n",
            "    \"Machine Learning\",\n",
            "    \"Statistical Modeling\"\n",
            "  ],\n",
            "  \"recent_roles\": [\n",
            "    {\n",
            "      \"title\": \"Independent Data and AI Scientist\",\n",
            "      \"company\": \"Freelance\",\n",
            "      \"duration\": \"July 2024 - Present\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Developer Relations\",\n",
            "      \"company\": \"Outerbounds\",\n",
            "      \"duration\": \"February 2022 - August 2024\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Data Science Evangelism and Marketing\",\n",
            "      \"company\": \"Coiled\",\n",
            "      \"duration\": \"May 2020 - October 2021\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": \"Doctor of Philosophy (PhD), Pure Mathematics from UNSW Australia\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# First, let's extract the candidate data using our best prompt\n",
        "def extract_profile_data(linkedin_text):\n",
        "    \"\"\"Extract structured JSON from LinkedIn profile text using our best prompt.\"\"\"\n",
        "    prompt = f\"\"\"Extract structured information from the LinkedIn profile below.\n",
        "\n",
        "Required fields:\n",
        "- name (string): Full name of the person\n",
        "- current_title (string): Most recent job title\n",
        "- location (string): Current location\n",
        "- years_experience (integer): Total years of professional experience\n",
        "- top_skills (array): 3-5 key skills or areas of expertise\n",
        "- recent_roles (array): 2-3 most recent positions with title, company, and duration\n",
        "- education (string): Highest degree and institution\n",
        "\n",
        "Important rules:\n",
        "- If a field is missing or unclear, use null for strings or [] for arrays\n",
        "- For years_experience, calculate from experience section dates\n",
        "- Extract skills from the profile text, skills section, or infer from roles\n",
        "- Return ONLY valid JSON, no markdown formatting\n",
        "\n",
        "<linkedin_profile>\n",
        "{linkedin_text}\n",
        "</linkedin_profile>\n",
        "\"\"\"\n",
        "    \n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt,\n",
        "        config={\n",
        "            \"response_mime_type\": \"application/json\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    return json.loads(response.text)\n",
        "\n",
        "# Extract candidate data\n",
        "candidate_data = extract_profile_data(linkedin_profile)\n",
        "print(\"=== Extracted Candidate Data ===\")\n",
        "print(json.dumps(candidate_data, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job we're recruiting for:\n",
            "Senior AI/ML Engineer\n",
            "Location: Remote (US-based)\n",
            "Salary: $180k-$250k + equity\n",
            "\n",
            "We're looking for an experienced AI/ML engineer to join our team building next-generation \n",
            "machine learning infrastructure. You'll work on scaling ML systems, building developer tools, \n",
            "and helping data scientists deploy models to production.\n",
            "\n",
            "Requirements:\n",
            "- 5+ years experience in ML/AI or data science\n",
            "- Strong Python skills\n",
            "- Experience with ML frameworks and infrastructure\n",
            "- Track record of building tools that others love to use\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Job description for context\n",
        "job_description = \"\"\"Senior AI/ML Engineer\n",
        "Location: Remote (US-based)\n",
        "Salary: $180k-$250k + equity\n",
        "\n",
        "We're looking for an experienced AI/ML engineer to join our team building next-generation \n",
        "machine learning infrastructure. You'll work on scaling ML systems, building developer tools, \n",
        "and helping data scientists deploy models to production.\n",
        "\n",
        "Requirements:\n",
        "- 5+ years experience in ML/AI or data science\n",
        "- Strong Python skills\n",
        "- Experience with ML frameworks and infrastructure\n",
        "- Track record of building tools that others love to use\n",
        "\"\"\"\n",
        "\n",
        "print(\"Job we're recruiting for:\")\n",
        "print(job_description)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Email Variation 1: Minimal (Baseline)\n",
        "\n",
        "Simple request with no specific guidance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ClientError",
          "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\\nPlease retry in 43.726781707s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m email_prompt_v1 = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mWrite a recruiter email to this candidate:\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mjson.dumps(candidate_data,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mjob_description\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m email_v1 = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.0-flash-exp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43memail_prompt_v1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Email V1: Minimal ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(email_v1.text)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/models.py:5218\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5216\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5217\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5218\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5219\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5220\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5222\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5223\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/models.py:4000\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3997\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   3998\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4000\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4005\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4006\u001b[39m ):\n\u001b[32m   4007\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1380\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1383\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1384\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1385\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m   response_body = (\n\u001b[32m   1390\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m   )\n\u001b[32m   1392\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/_api_client.py:1224\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/concurrent/futures/_base.py:443\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/concurrent/futures/_base.py:395\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1194\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m       method=http_request.method,\n\u001b[32m   1196\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-first-principles/lib/python3.14/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
            "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\\nPlease retry in 43.726781707s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}"
          ]
        }
      ],
      "source": [
        "email_prompt_v1 = f\"\"\"Write a recruiter email to this candidate:\n",
        "\n",
        "{json.dumps(candidate_data, indent=2)}\n",
        "\n",
        "Job:\n",
        "{job_description}\n",
        "\"\"\"\n",
        "\n",
        "email_v1 = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=email_prompt_v1,\n",
        ")\n",
        "\n",
        "print(\"=== Email V1: Minimal ===\")\n",
        "print(email_v1.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Email Variation 2: With Guardrails and Personalization Requirements\n",
        "\n",
        "This variation includes specific requirements and explicit guardrails about what NOT to include."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Email V2 ===\n",
            "Subject: AI/ML Infrastructure & Developer Tools – Hugo Bowne-Anderson\n",
            "\n",
            "Hi Hugo,\n",
            "\n",
            "I'm reaching out after reviewing your extensive background, particularly your 15 years as an Independent Data and AI Scientist and your leadership in Developer Relations at Outerbounds and Data Science Evangelism at Coiled. Your track record of making complex ML accessible and building tools that empower data scientists immediately caught my attention.\n",
            "\n",
            "We're building next-generation machine learning infrastructure, focusing on scaling ML systems and creating intuitive developer tools to help data scientists deploy models to production. Given your deep AI/ML expertise and your passion for developer enablement, I believe this Senior AI/ML Engineer role could be a compelling opportunity to leverage your skills in a foundational way.\n",
            "\n",
            "This remote position offers a chance to significantly impact our ML platform from the ground up, with competitive compensation and equity.\n",
            "\n",
            "Would you be open to a brief conversation to discuss if this aligns with your professional goals?\n"
          ]
        }
      ],
      "source": [
        "email_prompt_v2 = f\"\"\"You are a professional technical recruiter. Write a personalized outreach email.\n",
        "\n",
        "Candidate:\n",
        "{json.dumps(candidate_data, indent=2)}\n",
        "\n",
        "Job:\n",
        "{job_description}\n",
        "\n",
        "Guidelines:\n",
        "- Keep it under 250 words\n",
        "- Reference 2-3 specific things from their background\n",
        "- Explain why this role is a good fit for THEM (not just why they're good for us)\n",
        "- Professional and respectful tone\n",
        "- Include a clear subject line\n",
        "\n",
        "DO NOT:\n",
        "- Use phrases like \"I hope this email finds you well\" or \"exciting opportunity\"\n",
        "- Include salary information (mention \"competitive compensation\" only)\n",
        "- Make it sound like a form letter\n",
        "- Oversell or use excessive exclamation marks\n",
        "- Include your signature (just end with a question)\n",
        "\"\"\"\n",
        "\n",
        "email_v2 = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=email_prompt_v2,\n",
        ")\n",
        "\n",
        "print(\"=== Email V2 ===\")\n",
        "print(email_v2.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Two-Stage Pipeline\n",
        "\n",
        "Now let's combine both stages into a complete, reusable function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== COMPLETE PIPELINE TEST ===\n",
            "Stage 1: Extracting candidate data...\n",
            "Extracted candidate data\n",
            "{\n",
            "  \"name\": \"Hugo Bowne-Anderson\",\n",
            "  \"current_title\": \"Independent Data and AI Scientist\",\n",
            "  \"location\": \"Darlinghurst, New South Wales, Australia\",\n",
            "  \"years_experience\": 15,\n",
            "  \"top_skills\": [\n",
            "    \"Artificial Intelligence (AI)\",\n",
            "    \"Data Science\",\n",
            "    \"Developer Relations\"\n",
            "  ],\n",
            "  \"recent_roles\": [\n",
            "    {\n",
            "      \"title\": \"Independent Data and AI Scientist\",\n",
            "      \"company\": \"Freelance\",\n",
            "      \"duration\": \"July 2024 - Present (1 year 6 months)\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Developer Relations\",\n",
            "      \"company\": \"Outerbounds\",\n",
            "      \"duration\": \"February 2022 - August 2024 (2 years 7 months)\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Head of Data Science Evangelism and Marketing\",\n",
            "      \"company\": \"Coiled\",\n",
            "      \"duration\": \"May 2020 - October 2021 (1 year 6 months)\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": \"Doctor of Philosophy (PhD) in Pure Mathematics from UNSW Australia\"\n",
            "}\n",
            "\n",
            "Stage 2: Generating email...\n",
            "Generated email\n",
            "\n",
            "\n",
            "============================================================\n",
            "FINAL EMAIL:\n",
            "============================================================\n",
            "Subject: Senior AI/ML Engineer Role | Leveraging your DevRel & ML Infrastructure Expertise\n",
            "\n",
            "Hi Hugo,\n",
            "\n",
            "Your extensive background as an Independent Data and AI Scientist, coupled with your impactful roles as Head of Developer Relations at Outerbounds and Head of Data Science Evangelism at Coiled, immediately stood out.\n",
            "\n",
            "Our team is actively seeking a Senior AI/ML Engineer who can not only build robust next-generation machine learning infrastructure but also excels at crafting developer tools and enabling data scientists to deploy models effectively. Your specific experience in developer relations and evangelism, particularly in the data science space, directly aligns with our goal of building tools that others genuinely love to use.\n",
            "\n",
            "This remote role (US-based) offers a salary of $180k-$250k + equity, and presents an opportunity to apply your deep understanding of AI/ML with your proven ability to bridge complex technology with user adoption.\n",
            "\n",
            "If you're open to exploring a role where your blend of technical leadership and developer advocacy can make a significant impact on ML infrastructure, I'd be glad to share more details.\n",
            "\n",
            "Best,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n"
          ]
        }
      ],
      "source": [
        "def generate_recruiter_email_pipeline(linkedin_text, job_description):\n",
        "    \"\"\"Complete pipeline: LinkedIn text → Structured data → Personalized email\"\"\"\n",
        "    \n",
        "    # Stage 1: Extract structured data\n",
        "    print(\"Stage 1: Extracting candidate data...\")\n",
        "    candidate_data = extract_profile_data(linkedin_text)\n",
        "    print(\"Extracted candidate data\")\n",
        "    print(json.dumps(candidate_data, indent=2))\n",
        "    \n",
        "    # Stage 2: Generate email\n",
        "    print(\"\\nStage 2: Generating email...\")\n",
        "    email_prompt = f\"\"\"You are a professional technical recruiter. Write a personalized outreach email.\n",
        "\n",
        "Candidate:\n",
        "{json.dumps(candidate_data, indent=2)}\n",
        "\n",
        "Job:\n",
        "{job_description}\n",
        "\n",
        "Guidelines:\n",
        "- Keep it under 250 words\n",
        "- Reference 2-3 specific things from their background\n",
        "- Explain why this role is a good fit for THEM\n",
        "- Professional and respectful tone\n",
        "- Include a clear subject line\n",
        "\n",
        "DO NOT:\n",
        "- Use phrases like \"I hope this email finds you well\" or \"exciting opportunity\"\n",
        "- Make it sound like a form letter\n",
        "- Oversell or use excessive exclamation marks\n",
        "- Include your signature\n",
        "\"\"\"\n",
        "    \n",
        "    email_response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=email_prompt,\n",
        "    )\n",
        "    \n",
        "    print(\"Generated email\\n\")\n",
        "    return email_response.text\n",
        "\n",
        "# Test the complete pipeline\n",
        "print(\"=== COMPLETE PIPELINE TEST ===\")\n",
        "final_email = generate_recruiter_email_pipeline(linkedin_profile, job_description)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL EMAIL:\")\n",
        "print(\"=\"*60)\n",
        "print(final_email)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Judge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using an LLM to Evaluate Quality\n",
        "\n",
        "How do we check if our pipeline is working?\n",
        "\n",
        "*   **For Structured Data:** We can use **code-based checks** (e.g., `json.loads()` to verify the JSON is valid, or asserting that \"years_experience\" is an integer).\n",
        "*   **For Content Quality:** We can't use code to check if an email is \"polite\" or \"relevant.\" For this, we need **Judgment**.\n",
        "\n",
        "**The Solution:** Use an LLM as a \"Judge.\"\n",
        "\n",
        "In this section, we will demonstrate this pattern by evaluating a set of example emails. We'll define a rubric and ask the LLM to score them.\n",
        "\n",
        "**Exercise for the Reader:** After seeing how this works, try applying this judge to the actual output of the `generate_recruiter_email_pipeline` function we built above!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EVALUATOR_PROMPT = \"\"\"\n",
        "You are an expert evaluator assessing outputs from an outreach automation system\n",
        "that drafts personalized emails based on a recipient’s LinkedIn profile.\n",
        "\n",
        "Your Task:\n",
        "Determine if the assistant-generated outreach email is appropriately personalized\n",
        "and relevant to the recipient’s background and role, as described in their LinkedIn profile.\n",
        "\n",
        "Evaluation Criterion:\n",
        "Personalization and Relevance\n",
        "\n",
        "Definition of Pass/Fail:\n",
        "- Fail: The email is generic, irrelevant, or mismatched to the recipient’s background,\n",
        "  interests, or role. It could have been sent to anyone.\n",
        "- Pass: The email clearly demonstrates understanding of the recipient’s professional\n",
        "  background, role, or achievements. It references specific details from the profile\n",
        "  and establishes a relevant connection or value proposition.\n",
        "\n",
        "Profile Dimensions to Consider:\n",
        "- Current role and industry\n",
        "- Skills, interests, or accomplishments\n",
        "- Relevance of the email’s purpose to the recipient’s background\n",
        "\n",
        "Output Format:\n",
        "Return your evaluation as a JSON object with two keys:\n",
        "1. reasoning: A brief explanation (1–2 sentences) for your decision.\n",
        "2. answer: Either \"Pass\" or \"Fail\".\n",
        "\n",
        "Examples:\n",
        "---\n",
        "Input 1:\n",
        "LinkedIn Summary:\n",
        "\"Head of Data Science at FinEdge. I lead teams building predictive models for\n",
        "credit scoring and fraud detection. Passionate about applying ML in finance.\"\n",
        "\n",
        "Generated Email:\n",
        "\"Hey there! I’m reaching out to connect and share a few exciting updates from our AI team.\n",
        "We’ve been working on some cool tools for startups and would love to get your feedback!\"\n",
        "\n",
        "Evaluation:\n",
        "{\n",
        "  \"reasoning\": \"The email is generic and makes no reference to the recipient’s background in\n",
        "  financial ML or leadership. It could have been sent to anyone.\",\n",
        "  \"answer\": \"Fail\"\n",
        "}\n",
        "---\n",
        "Input 2:\n",
        "LinkedIn Summary:\n",
        "\"Head of Data Science at FinEdge. I lead teams building predictive models for\n",
        "credit scoring and fraud detection. Passionate about applying ML in finance.\"\n",
        "\n",
        "Generated Email:\n",
        "\"Hi Alex, I saw your work leading the data science team at FinEdge on credit scoring and\n",
        "fraud detection—really impressive. We’ve built a platform for managing ML model drift\n",
        "in financial institutions, and I’d love to hear your thoughts.\"\n",
        "\n",
        "Evaluation:\n",
        "{\n",
        "  \"reasoning\": \"The email references the recipient’s leadership role and domain focus, and\n",
        "  clearly connects the product to financial ML applications.\",\n",
        "  \"answer\": \"Pass\"\n",
        "}\n",
        "---\n",
        "Now, evaluate the following:\n",
        "\n",
        "LinkedIn Summary: {{LINKEDIN_SUMMARY_HERE}}\n",
        "Generated Email: {{GENERATED_EMAIL_HERE}}\n",
        "\n",
        "Your JSON Evaluation:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example emails to evaluate\n",
        "examples = [\n",
        "    {\n",
        "        \"linkedin_summary\": \"Senior ML Engineer at TechCorp specializing in NLP and conversational AI. 5 years experience building production models.\",\n",
        "        \"email\": \"\"\"Subject: Your NLP work at TechCorp\n",
        "\n",
        "Hi Sarah,\n",
        "\n",
        "I saw your work on conversational AI at TechCorp and was particularly impressed by your focus on production ML systems. We're building an evaluation platform specifically for NLP models in production, and your experience with both model development and deployment would be invaluable.\n",
        "\n",
        "Would you be open to a brief conversation about the challenges you've faced with model evaluation?\n",
        "\n",
        "Best,\n",
        "Alex\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"linkedin_summary\": \"Senior ML Engineer at TechCorp specializing in NLP and conversational AI. 5 years experience building production models.\",\n",
        "        \"email\": \"\"\"Subject: Exciting opportunity!\n",
        "\n",
        "Hi there!\n",
        "\n",
        "I hope this email finds you well! We have an amazing opportunity in AI/ML that would be perfect for talented engineers like yourself.\n",
        "\n",
        "Our company is doing cutting-edge work and we'd love to chat. Let me know if you're interested!\n",
        "\n",
        "Thanks,\n",
        "Mike\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"linkedin_summary\": \"Senior ML Engineer at TechCorp specializing in NLP and conversational AI. 5 years experience building production models.\",\n",
        "        \"email\": \"\"\"Subject: ML position\n",
        "\n",
        "Hi,\n",
        "\n",
        "We're hiring ML engineers. You have ML experience so thought I'd reach out. The role involves building models and working with data.\n",
        "\n",
        "Interested?\n",
        "\n",
        "Thanks,\n",
        "Jen\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"linkedin_summary\": \"Senior ML Engineer at TechCorp specializing in NLP and conversational AI. 5 years experience building production models.\",\n",
        "        \"email\": \"\"\"Subject: ML role\n",
        "\n",
        "Hi Sarah,\n",
        "\n",
        "We're hiring ML engineers and saw you have ML experience. The role involves building models and working with data.\n",
        "\n",
        "Let me know if you're interested.\n",
        "\n",
        "Thanks,\n",
        "Tom\"\"\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EMAIL 1\n",
            "============================================================\n",
            "Subject: Your NLP work at TechCorp\n",
            "\n",
            "Hi Sarah,\n",
            "\n",
            "I saw your work on conversational AI at TechCorp and was particularly impressed by your focus on production ML systems. We're building an evaluation platform specifically for NLP models in production, and your experience with both model development and deployment would be invaluable.\n",
            "\n",
            "Would you be open to a brief conversation about the challenges you've faced with model evaluation?\n",
            "\n",
            "Best,\n",
            "Alex\n",
            "\n",
            "✓ Judgment: Pass\n",
            "Reasoning: The email directly references the recipient's specialization in conversational AI and experience with production ML systems at TechCorp, aligning the product (NLP model evaluation platform) with their background.\n",
            "\n",
            "============================================================\n",
            "EMAIL 2\n",
            "============================================================\n",
            "Subject: Exciting opportunity!\n",
            "\n",
            "Hi there!\n",
            "\n",
            "I hope this email finds you well! We have an amazing opportunity in AI/ML that would be perfect for talented engineers like yourself.\n",
            "\n",
            "Our company is doing cutting-edge work and we'd love to chat. Let me know if you're interested!\n",
            "\n",
            "Thanks,\n",
            "Mike\n",
            "\n",
            "✓ Judgment: Fail\n",
            "Reasoning: The email is completely generic and makes no reference to the recipient's specific specialization in NLP, conversational AI, or their experience with production models. It could be sent to any ML engineer.\n",
            "\n",
            "============================================================\n",
            "EMAIL 3\n",
            "============================================================\n",
            "Subject: ML position\n",
            "\n",
            "Hi,\n",
            "\n",
            "We're hiring ML engineers. You have ML experience so thought I'd reach out. The role involves building models and working with data.\n",
            "\n",
            "Interested?\n",
            "\n",
            "Thanks,\n",
            "Jen\n",
            "\n",
            "✓ Judgment: Fail\n",
            "Reasoning: The email is generic, only stating 'ML experience' and making no reference to the recipient's senior role, specialization in NLP/conversational AI, or specific company.\n",
            "\n",
            "============================================================\n",
            "EMAIL 4\n",
            "============================================================\n",
            "Subject: ML role\n",
            "\n",
            "Hi Sarah,\n",
            "\n",
            "We're hiring ML engineers and saw you have ML experience. The role involves building models and working with data.\n",
            "\n",
            "Let me know if you're interested.\n",
            "\n",
            "Thanks,\n",
            "Tom\n",
            "\n",
            "✓ Judgment: Fail\n",
            "Reasoning: The email is generic, only referencing 'ML experience' without any specific mention of the recipient's specialization in NLP, conversational AI, or their senior role and experience. It could have been sent to any ML engineer.\n"
          ]
        }
      ],
      "source": [
        "from google.genai import types\n",
        "\n",
        "for i, example in enumerate(examples, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EMAIL {i}\")\n",
        "    print('='*60)\n",
        "    print(example['email'])\n",
        "    \n",
        "    judge_prompt = EVALUATOR_PROMPT.replace(\"{{LINKEDIN_SUMMARY_HERE}}\", example['linkedin_summary']).replace(\"{{GENERATED_EMAIL_HERE}}\", example['email'])\n",
        "    \n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=judge_prompt,\n",
        "        config=types.GenerateContentConfig(response_mime_type='application/json')\n",
        "    )\n",
        "    \n",
        "    evaluation = json.loads(response.text)\n",
        "    print(f\"\\n✓ Judgment: {evaluation['answer']}\")\n",
        "    print(f\"Reasoning: {evaluation['reasoning']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we moved beyond simple queries and built a **Two-Stage Pipeline**:\n",
        "\n",
        "1.  **Structured Extraction:** We tamed unstructured text (LinkedIn profiles) into clean, usable JSON data.\n",
        "2.  **Grounded Generation:** We used that structured data to generate highly personalized content (emails), using specific constraints to control the tone.\n",
        "3.  **Automated Evaluation:** We explored the **LLM-as-a-Judge** pattern to automatically assess quality, allowing us to judge \"fuzzy\" metrics like relevance and tone that standard code tests miss.\n",
        "\n",
        "This gives us the building blocks for creating more reliable and testable AI applications."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "genai-first-principles",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
